wh.col <- c(4:5, 12, 15, 18:21, 23:25)
getwd()
file.name <- 'authority.csv'
if(!file.exists(file.name)) {
file.create(file.name)
}
setwd('..')
file.names <- sprintf('authority2009.part%02d', 0:17)
file.names
require(author-ity_reader)
require(authority_reader)
pkgs <- c('R.utils', 'data.table')
?require
for(pkg in pkgs) {
if(!require(pkg, character.only = TRUE)) {
install.packages(pkg)
stopifnot(require(pkg, character.only = TRUE))
}
}
authority.files <- 'authority2009.100.txt'
wh.col <- c(4:5, 12, 15, 18:21, 23:25)
no.lines <- 9
file.name <- 'authority.csv'
if(!file.exists(file.name)) {
file.create(file.name)
}
file.name <- 'data/authority.csv'
if(!file.exists(file.name)) {
file.create(file.name)
}
?readLines
file=authority.files[1]
n <- 0
N <- countLines(file)
file.name <- 'data/authority.csv'
if(!file.exists(file.name)) {
file.create(file.name)
}
authority.files
#authority.files <- 'data/authority2009.100.txt'
authority.files <- 'data/authority2009.100.txt'
n <- 0
N <- countLines(file)
file=authority.files[1]
n <- 0
N <- countLines(file)
N
length(N)
N=5
N <- countLines(file)
N==5
n+5
N+5
unname(N)
N>n
n
lines <- readLines(file, n = no.lines)
n <- n + length(lines)
fields <- subsplit(lines, '\t', wh.col)
#' Split lines and keep only certain entries
#'
#' This function splits a list or vector of lines by a pattern but includes only
#' certain entries in the output (all of which must be present in each split
#' string).
#' @param x Vector or list of strings (to be fed to `strsplit`)
#' @param pattern Character string
#' @param inds Numerical vector; entries of each `strsplit` to keep
#' @export
subsplit <- function(x, pattern, inds = 1) {
lapply(strsplit(x, pattern), function(vec) vec[inds])
}
fields <- subsplit(lines, '\t', wh.col)
fields
sapply(fields,length)
as.data.frame(fields)
as.data.frame(fields)->test
dim(test)
unname(test)
test[, c(1,3)]
test[, c(1,4)]
test[, c(2,4)]
test[, c(8,9)]
test[, c(9,10)]
sapply(fields,length)
do.call(rbind, fields)
do.call(rbind, fields)->test
mode(test)
test[, c(9,10)]
test[, c(9,11)]
test[, c(8,11)]
test[, c(9,11)]
test[, c(7,11)]
test[, c(6,11)]
test[, c(5,11)]
test[, c(4,11)]
write(test,file.name)
write(as.data.frame(test),file.name)
as.data.frame(test)->test2
head(test2)
write.table(as.data.frame(test),file.name)
write.csv(as.data.frame(test),file.name)
mat <- do.call(rbind, subsplit(lines, '\t', wh.col))
dim(mat)
?write.csv
new.file <- 'data/authority.csv'
if(!file.exists(new.file)) {
file.create(new.file)
}
write.csv(as.data.frame(mat), file = new.file, append = TRUE,
quote = FALSE, sep = ',')
new.file <- 'data/authority.csv'
if(!file.exists(new.file)) {
file.create(new.file)
}
write.table(as.data.frame(mat), file = new.file, append = TRUE,
quote = FALSE, sep = ',')
col.names <- c(
author, no.papers, years, journals, coauthors, papers, grants, citations
, no.citations, cited, cited.by
)
col.names <- c(
'author', 'no.papers', 'years', 'journals', 'coauthors', 'papers', 'grants'
, 'citations', 'no.citations', 'cited', 'cited.by'
)
stopifnot(length(wh.col) length(col.names))
stopifnot(length(wh.col) == length(col.names))
?write
new.file <- 'data/authority.csv'
write(col.names, file = new.file)
write(col.names, file = new.file, append = FALSE, sep = ',')
write(col.names, file = new.file, ncolumns = length(col.names),
append = FALSE, sep = ',')
n <- 0
N <- countLines(file)
lines <- readLines(file, n = no.lines)
n <- n + length(lines)
mat <- do.call(rbind, subsplit(lines, '\t', wh.col))
?write.table
write.table(as.data.frame(mat), file = new.file, append = TRUE,
quote = FALSE, sep = ',',
row.names = FALSE, col.names = FALSE)
rm(list=ls())
# authority file names
authority.files <- sprintf('authority2009.part%02d', 0:17)
#authority.files <- 'data/authority2009.100.txt'
# which fields to include
wh.col <- c(4:5, 12, 15, 18:21, 23:25)
col.names <- c(
'author', 'no.papers', 'years', 'journals', 'coauthors', 'papers', 'grants'
, 'citations', 'no.citations', 'cited', 'cited.by'
)
stopifnot(length(wh.col) == length(col.names))
# how many lines to read at a time
no.lines <- 9
# initialize empty file
new.file <- 'data/authority.csv'
write(col.names, file = new.file, ncolumns = length(col.names),
append = FALSE, sep = ',')
# for each authority file, in batches of no.lines:
for(file in authority.files) {
n <- 0
N <- countLines(file)
while(N > n) {
lines <- readLines(file, n = no.lines)
n <- n + length(lines)
mat <- do.call(rbind, subsplit(lines, '\t', wh.col))
write.table(as.data.frame(mat), file = new.file, append = TRUE,
quote = FALSE, sep = ',',
row.names = FALSE, col.names = FALSE)
}
}
authority.files <- 'data/authority2009.100.txt'
wh.col <- c(4:5, 12, 15, 18:21, 23:25)
col.names <- c(
'author', 'no.papers', 'years', 'journals', 'coauthors', 'papers', 'grants'
, 'citations', 'no.citations', 'cited', 'cited.by'
)
stopifnot(length(wh.col) == length(col.names))
no.lines <- 9
new.file <- 'data/authority.csv'
write(col.names, file = new.file, ncolumns = length(col.names),
append = FALSE, sep = ',')
for(file in authority.files) {
n <- 0
N <- countLines(file)
while(N > n) {
lines <- readLines(file, n = no.lines)
n <- n + length(lines)
mat <- do.call(rbind, subsplit(lines, '\t', wh.col))
write.table(as.data.frame(mat), file = new.file, append = TRUE,
quote = FALSE, sep = ',',
row.names = FALSE, col.names = FALSE)
}
}
?list.files
fns <- list.files('R/')
fns
for(fn in fns) {
source(paste0('R/', fn))
}
authority.files <- sprintf('authority2009.part%02d', 0:17)
wh.col <- c(4:5, 12, 15, 18:21, 23:25)
col.names <- c(
'author', 'no.papers', 'years', 'journals', 'coauthors', 'papers', 'grants'
, 'citations', 'no.citations', 'cited', 'cited.by'
)
stopifnot(length(wh.col) == length(col.names))
no.lines <- 9
new.file <- 'data/authority.csv'
write(col.names, file = new.file, ncolumns = length(col.names),
append = FALSE, sep = ',')
for(file in authority.files) {
n <- 0
N <- countLines(file)
while(N > n) {
lines <- readLines(file, n = no.lines)
n <- n + length(lines)
mat <- do.call(rbind, subsplit(lines, '\t', wh.col))
write.table(as.data.frame(mat), file = new.file, append = TRUE,
quote = FALSE, sep = ',',
row.names = FALSE, col.names = FALSE)
}
}
authority.files <- 'data/authority2009.100.txt'
# initialize empty file
new.file <- 'data/authority.csv'
write(col.names, file = new.file, ncolumns = length(col.names),
append = FALSE, sep = ',')
for(file in authority.files) {
n <- 0
N <- countLines(file)
while(N > n) {
lines <- readLines(file, n = no.lines)
n <- n + length(lines)
mat <- do.call(rbind, subsplit(lines, '\t', wh.col))
write.table(as.data.frame(mat), file = new.file, append = TRUE,
quote = FALSE, sep = ',',
row.names = FALSE, col.names = FALSE)
}
}
?read.table
test <- read.csv(new.file))
test <- read.csv(new.file)
head(test)
dim(test)
tail(test)
names(test)
mode(test)
is.data.frame(test)
dim(test)
which(is.na(test))
which(is.na(as.matrix(test)))
sapply(test[, 5], nchar)
sapply(as.character(test[, 5]), nchar)
unname(sapply(as.character(test[, 5]), nchar))
unname(sapply(as.character(test[, 4]), nchar))
unname(sapply(as.character(test[, 3]), nchar))
unname(test[, 3])
?read.csv
test <- read.csv(new.file, nrows = 100)
dim(test)
pkgs <- c('R.utils', 'data.table', 'parallel')
for(pkg in pkgs) {
if(!require(pkg, character.only = TRUE)) {
install.packages(pkg)
stopifnot(require(pkg, character.only = TRUE))
}
}
# read functions from pending authority_graph package
fns <- list.files('R/')
for(fn in fns) {
source(paste0('R/', fn))
}
?parLapply
?makeCluster
cl <- makeCluster(spec = 'localhost', type = 'SOCK')
install.packages('snow')
cl <- makeCluster(spec = 'localhost', type = 'SOCK')
cl
cl <- makeCluster(spec = rep('localhost', 4), type = 'SOCK')
cl
cl <- makeCluster(spec = rep('localhost', 5), type = 'SOCK')
cl <- makeCluster(spec = rep('localhost', 4), type = 'SOCK')
parLapply(cl, 1:20, function(x) x^2)
detectCores()[[1]]
#' Split lines and keep only certain entries
#'
#' This function splits a list or vector of lines by a pattern but includes only
#' certain entries in the output (all of which must be present in each split
#' string).
#' @param x Vector or list of strings (to be fed to `strsplit`)
#' @param pattern Character string
#' @param inds Numerical vector; entries of each `strsplit` to keep
#' @export
subsplit <- function(x, pattern, inds = 1, parallel, cl) {
if(parallel) {
stopifnot(require(snow))
stopifnot(require(parallel))
if(missing(cl)) cl <- makeCluster(rep('localhost', detectCores()[[1]]))
parLapply(cl, strsplit(x, pattern), function(vec) vec[inds])
}
lapply(strsplit(x, pattern), function(vec) vec[inds])
}
#' Split lines and keep only certain entries
#'
#' This function splits a list or vector of lines by a pattern but includes only
#' certain entries in the output (all of which must be present in each split
#' string).
#' @param x Vector or list of strings (to be fed to `strsplit`)
#' @param pattern Character string
#' @param inds Numerical vector; entries of each `strsplit` to keep
#' @export
subsplit <- function(x, pattern, inds = 1, parallel = !missing(cl), cl) {
if(parallel) {
stopifnot(require(snow))
stopifnot(require(parallel))
if(missing(cl)) cl <- makeCluster(rep('localhost', detectCores()[[1]]))
parLapply(cl, strsplit(x, pattern), function(vec) vec[inds])
}
lapply(strsplit(x, pattern), function(vec) vec[inds])
}
setwd('~/Documents/CQM/medline/authority_graph')
pkgs <- c('R.utils', 'data.table', 'snow', 'parallel')
for(pkg in pkgs) {
if(!require(pkg, character.only = TRUE)) {
install.packages(pkg)
stopifnot(require(pkg, character.only = TRUE))
}
}
# read functions from pending authority_graph package
fns <- list.files('R/')
for(fn in fns) {
source(paste0('R/', fn))
}
cl <- makeCluster(spec = rep('localhost', 4), type = 'SOCK')
cl
authority.files <- 'data/authority2009.100.txt'
wh.col <- c(4:5, 12, 15, 18:21, 23:25)
col.names <- c(
'author', 'no.papers', 'years', 'journals', 'coauthors', 'papers', 'grants'
, 'citations', 'no.citations', 'cited', 'cited.by'
)
stopifnot(length(wh.col) == length(col.names))
no.lines <- 100
dir.create('data')
new.file <- 'data/authority.csv'
write(col.names, file = new.file, ncolumns = length(col.names),
append = FALSE, sep = ',')
for(file in authority.files) {
n <- 0
N <- 1000#countLines(file)
while(N > n) {
lines <- readLines(file, n = no.lines)
n <- n + length(lines)
mat <- do.call(rbind, subsplit(lines, '\t', wh.col, cl = cl))
write.table(as.data.frame(mat), file = new.file, append = TRUE,
quote = FALSE, sep = ',',
row.names = FALSE, col.names = FALSE)
}
}
wh.col
for(file in authority.files) {
n <- 0
N <- 1000#countLines(file)
while(N > n) {
lines <- readLines(file, n = no.lines)
n <- n + length(lines)
mat <- do.call(rbind, subsplit(lines, '\t', wh.col))
write.table(as.data.frame(mat), file = new.file, append = TRUE,
quote = FALSE, sep = ',',
row.names = FALSE, col.names = FALSE)
}
}
n <- 0
N <- 1000#countLines(file)
file=authority.files[1]
file
lines <- readLines(file, n = no.lines)
n <- n + length(lines)
mat <- do.call(rbind, subsplit(lines, '\t', wh.col, cl = cl))
#' Split lines and keep only certain entries
#'
#' This function splits a list or vector of lines by a pattern but includes only
#' certain entries in the output (all of which must be present in each split
#' string).
#' @param x Vector or list of strings (to be fed to `strsplit`)
#' @param pattern Character string
#' @param inds Numerical vector; entries of each `strsplit` to keep
#' @export
subsplit <- function(x, pattern, inds = 1, parallel = !missing(cl), cl) {
if(parallel) {
stopifnot(require(snow))
stopifnot(require(parallel))
if(missing(cl)) cl <- makeCluster(rep('localhost', detectCores()[[1]]))
parLapply(cl, strsplit(x, pattern), function(vec) vec[inds])
}
lapply(strsplit(x, pattern), function(vec) vec[inds])
}
mat <- do.call(rbind, subsplit(lines, '\t', wh.col, cl = cl))
x=lines
pattern='\t'
inds=wh.col
mat <- do.call(rbind, subsplit(lines, '\t', inds = wh.col, cl = cl))
cl
parallel = !missing(cl)
parallel
#' Split lines and keep only certain entries
#'
#' This function splits a list or vector of lines by a pattern but includes only
#' certain entries in the output (all of which must be present in each split
#' string).
#' @param x Vector or list of strings (to be fed to `strsplit`)
#' @param pattern Character string
#' @param inds Numerical vector; entries of each `strsplit` to keep
#' @export
subsplit <- function(x, pattern, inds = 1, cl, parallel = !missing(cl)) {
if(parallel) {
stopifnot(require(snow))
stopifnot(require(parallel))
if(missing(cl)) cl <- makeCluster(rep('localhost', detectCores()[[1]]))
parLapply(cl, strsplit(x, pattern), function(vec) vec[inds])
}
lapply(strsplit(x, pattern), function(vec) vec[inds])
}
mat <- do.call(rbind, subsplit(lines, '\t', inds = wh.col, cl = cl))
stopifnot(require(snow))
stopifnot(require(parallel))
parLapply(cl, strsplit(x, pattern), function(vec) vec[inds])
inds
## Construct a large flat file for the following Author-ity fields:
# 4. Author-ity ID (AID) of author
# 5. number of author instances
# 12. range of years
# 15. names of journals (count)
# 18. AIDs of co-authors (count)
# 19. PMIDs of author instances
# 20. grant IDs
# 21. total citations
# 23. PMIDs by the author that have been cited (count)
# 24. PMIDs that the author cited (count)
# 25. PMIDs that cited the author (count)
# set working directory
setwd('~/medline/authority/')
#setwd('~/Documents/CQM/medline/authority_graph')
# load packages
pkgs <- c('R.utils', 'data.table', 'snow', 'parallel')
for(pkg in pkgs) {
if(!require(pkg, character.only = TRUE)) {
install.packages(pkg)
stopifnot(require(pkg, character.only = TRUE))
}
}
# read functions from pending authority_graph package
fns <- list.files('R/')
for(fn in fns) {
source(paste0('R/', fn))
}
# authority file names
authority.files <- sprintf('authority2009.part%02d', 0:17)
#authority.files <- 'data/authority2009.100.txt'
# which fields to include
wh.col <- c(4:5, 12, 15, 18:21, 23:25)
col.names <- c(
'author', 'no.papers', 'years', 'journals', 'coauthors', 'papers', 'grants'
, 'citations', 'no.citations', 'cited', 'cited.by'
)
stopifnot(length(wh.col) == length(col.names))
# how many lines to read at a time
no.lines <- 100
# initialize empty file
dir.create('data')
new.file <- 'data/authority.csv'
write(col.names, file = new.file, ncolumns = length(col.names),
append = FALSE, sep = ',')
authority.files <- 'data/authority2009.100.txt'
setwd('~/Documents/CQM/medline/authority_graph')
clusterExport(cl, lines)
for(file in authority.files) {
n <- 0
N <- 1000#countLines(file)
clusterExport(cl, 'N')
while(N > n) {
lines <- readLines(file, n = no.lines)
n <- n + length(lines)
clusterExport(cl, c('lines', 'n', 'wh.col'))
mat <- do.call(rbind, subsplit(lines, '\t', inds = wh.col, cl = cl))
write.table(as.data.frame(mat), file = new.file, append = TRUE,
quote = FALSE, sep = ',',
row.names = FALSE, col.names = FALSE)
}
}
